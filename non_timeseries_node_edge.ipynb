{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import chdir\n",
    "print(os.getcwd())\n",
    "chdir('C:\\\\Users\\\\eric\\\\Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"01.HealthCare_CPC_List.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CPC_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G06F21/6245, G06F19/323, G06F21/78, G06Q50/24,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G06F19/321, G06Q10/10, G06Q50/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G05B19/042, G05B2219/23043, G05B2219/23044, G0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G06Q50/22, G06F19/322, G06Q10/10, G06Q50/24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H04M3/5183, H04M3/42323, H04M3/5232, H04M3/54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            CPC_list\n",
       "0  G06F21/6245, G06F19/323, G06F21/78, G06Q50/24,...\n",
       "1                   G06F19/321, G06Q10/10, G06Q50/22\n",
       "2  G05B19/042, G05B2219/23043, G05B2219/23044, G0...\n",
       "3        G06Q50/22, G06F19/322, G06Q10/10, G06Q50/24\n",
       "4      H04M3/5183, H04M3/42323, H04M3/5232, H04M3/54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Execution_time :', 0.11400008201599121)\n",
      "           label  count  id\n",
      "0      G06F3/023      7   0\n",
      "1    H04L63/0435      1   1\n",
      "2       G07C3/00     11   2\n",
      "3      A61B5/681      7   3\n",
      "4  A61M2205/3393      2   4\n",
      "   Source_Label Target_Label  weight  Source  Target        Type\n",
      "0    A01K11/006   A61B5/1112       1    1905    1140  Undirected\n",
      "69   A01K11/006    A61B5/117       1    1905     321  Undirected\n",
      "23   A01K11/006   A61B5/1171       1    1905     140  Undirected\n",
      "77   A01K11/006    A61B5/411       1    1905    1836  Undirected\n",
      "27   A01K11/006    A61B5/681       1    1905       3  Undirected\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "# node edge\n",
    "def MakingEdgeNodelist(keyword_vec,sep_sign):\n",
    "    # (1) Keyword list (data set for combination)\n",
    "    keywords_list =[]\n",
    "    for words in keyword_vec:\n",
    "        #print(\"words :\", words)\n",
    "        split_words = words.split(sep_sign) # sep_sign으로 구분된 데이터를 분리하여\n",
    "        split_words = [ x.replace(\" \",\"\") for x in split_words]                                                # 리스트로 저장\n",
    "        soted_words = sorted(split_words) # ordering\n",
    "        keywords_list.append(soted_words)\n",
    "\n",
    "    # (2) Combination\n",
    "    comb_list = []\n",
    "    for i in keywords_list:\n",
    "        for subset in itertools.combinations(i, 2):\n",
    "            if subset[0] != subset[1]: # 같은 단어의 컴비네이션 제외\n",
    "                comb_list.append(subset)\n",
    "\n",
    "    # (3) Make dict & count\n",
    "    comb_count = {}\n",
    "    for combi in comb_list:\n",
    "        comb_count[combi] = comb_count.get(combi,0)+1\n",
    "\n",
    "    # (4) dic to df\n",
    "    comb_df = pd.DataFrame()\n",
    "\n",
    "    ## (4-1) dic_key to list\n",
    "    comb_keylist = []\n",
    "    for key in comb_count.keys():\n",
    "        combkey_tolist = list(key)\n",
    "        comb_keylist.append(combkey_tolist)\n",
    "\n",
    "    ## (4-2) dic_key split\n",
    "    source_list = []\n",
    "    target_list = []\n",
    "    for i in range(len(comb_keylist)):\n",
    "        source = comb_keylist[i][0]\n",
    "        target = comb_keylist[i][1]\n",
    "\n",
    "        source_list.append(source)\n",
    "        target_list.append(target)\n",
    "\n",
    "    comb_df['Source_Label'] = source_list\n",
    "    comb_df['Target_Label'] = target_list\n",
    "    comb_df['weight'] = comb_count.values()\n",
    "    \n",
    "\n",
    "    comb_df = comb_df.sort_values('Source_Label',axis=0).reset_index(drop=True)\n",
    "\n",
    "    # (5) node data\n",
    "    total_tech_list = []\n",
    "    for tech_li in keywords_list:\n",
    "        tech = list(set(tech_li))\n",
    "        total_tech_list.extend(tech)\n",
    "    # node_data = pd.concat([comb_df['Source_Label'],comb_df['Target_Label']],axis=0) # 총 출현 기술 ; 잘못됨을 확인함\n",
    "\n",
    "    node_df = pd.DataFrame()\n",
    "\n",
    "    node_count = {}\n",
    "    for node in total_tech_list:\n",
    "        node_count[node] = node_count.get(node,0)+1\n",
    "\n",
    "    node_df['label'] = node_count.keys()\n",
    "    node_df['count'] = node_count.values()\n",
    "    node_df['id'] = node_df.index\n",
    "    \n",
    "\n",
    "    # (6) make id\n",
    "    node_id = node_df[['label','id']]\n",
    "    node_id.columns = ['Source_Label','Source']\n",
    "\n",
    "    merge_sid = pd.merge(comb_df,node_id,how = 'inner')\n",
    "\n",
    "    node_id.columns = ['Target_Label','Target']\n",
    "\n",
    "    merge_tid = pd.merge(merge_sid,node_id,how = 'inner') # merge 과정에서 순서가 바뀜\n",
    "\n",
    "    edge_df = merge_tid.sort_values(['Source_Label','Target_Label'])\n",
    "\n",
    "    edge_df['Type'] = ['Undirected']*len(edge_df)\n",
    "\n",
    "    #edge_cols = ['Source','Target','weight','Type','Source_Label','Target_Label']\n",
    "    #edgelist = edgelist[edge_cols]\n",
    "\n",
    "    return(edge_df,node_df)\n",
    "\n",
    "\n",
    "# ipc 개수 2 이상인 데이터 필터링\n",
    "cpc_len = [ len(x.split(\",\")) for x in data.CPC_list]\n",
    "\n",
    "data['cpc_len'] = cpc_len\n",
    "\n",
    "dataset = data.loc[data.cpc_len>1] # , 로 구분되니 한개짜리는 떨군다.\n",
    "\n",
    "# edge / node list\n",
    "edge_list = pd.DataFrame()\n",
    "node_list = pd.DataFrame()\n",
    "\n",
    "s_time = time.time()\n",
    "#타임시리즈와다르게for문이필요가없다.\n",
    "doc = dataset['CPC_list']\n",
    "\n",
    "edge_part,node_part = MakingEdgeNodelist(doc,',')\n",
    "\n",
    "edge_list = pd.concat([edge_list,edge_part],axis=0)\n",
    "\n",
    "node_list = pd.concat([node_list,node_part],axis=0)\n",
    "    \n",
    "e_time = time.time()\n",
    "print(\"Execution_time :\",e_time - s_time)\n",
    "\n",
    "#\n",
    "print(node_list.head())\n",
    "print(edge_list.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list.to_csv(\"node_list_eric.csv\",index=False)\n",
    "edge_list.to_csv(\"edge_list_eric.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
